# Airflow Webserver:     kubectl port-forward svc/my-airflow-webserver 8080:8080 --namespace default
# Flower dashboard:      kubectl port-forward svc/my-airflow-flower 5555:5555 --namespace default
# Default Webserver (Airflow UI) Login credentials:
#     username: admin
#     password: admin
# Default Postgres connection credentials:
#     username: postgres
#     password: postgres
#     port: 5432

---
# Source: airflow/templates/secrets/fernetkey-secret.yaml


################################
## Airflow Fernet Key Secret
#################################

kind: Secret
apiVersion: v1
metadata:
  name: my-airflow-fernet-key
  labels:
    tier: airflow
    release: my-airflow
    chart: airflow
    heritage: Helm
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
type: Opaque
data:
  fernet-key: "VEhoc2VtWkpaM1ZxTm5KSk1YazNiazlWZFVwaU9WcGllV1ozVVd4YVJGVT0="
---
# Source: airflow/templates/secrets/redis-secrets.yaml


# We will create these secrets (if necessary) _even if_ we aren't
# currently using CeleryExecutor or CeleryKubernetesExecutor. As we are
# relying on the "pre-install" hack to prevent changing randomly generated passwords,
# updating the executor later doesn't give us the opportunity to deploy them
# when we need them. We will always deploy them defensively to make the executor
# update path actually work.

################################
## Airflow Redis Password Secret
#################################
# If passwordSecretName is not set, we will either use the set password, or use the generated one
kind: Secret
apiVersion: v1
metadata:
  name: my-airflow-redis-password
  labels:
    tier: airflow
    component: redis
    release: my-airflow
    chart: airflow
    heritage: Helm
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
type: Opaque
data:
  password: "QTJsdDhHN3R4NA=="
---
# Source: airflow/templates/secrets/redis-secrets.yaml
##################################
## Airflow Redis Connection Secret
##################################
kind: Secret
apiVersion: v1
metadata:
  name: my-airflow-broker-url
  labels:
    tier: airflow
    component: redis
    release: my-airflow
    chart: airflow
    heritage: Helm
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
type: Opaque
data:
  connection: "cmVkaXM6Ly86QTJsdDhHN3R4NEBteS1haXJmbG93LXJlZGlzOjYzNzkvMA=="
---
# Source: airflow/templates/jobs/create-user-job.yaml


################################
## Airflow Create User Job
#################################
apiVersion: batch/v1
kind: Job
metadata:
  name: my-airflow-create-user
  labels:
    tier: airflow
    component: create-user-job
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
    helm.sh/hook-weight: "2"
spec:
  template:
    metadata:
      labels:
        tier: airflow
        component: create-user-job
        release: my-airflow
    spec:
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      restartPolicy: OnFailure
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      serviceAccountName: my-airflow-create-user-job
      containers:
        - name: create-user
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - |-
              exec \
              airflow users create "$@"
            - --
            - -r
            - 'Admin'
            - -u
            - 'admin'
            - -e
            - 'admin@example.com'
            - -f
            - 'admin'
            - -l
            - 'user'
            - -p
            - 'admin'
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: my-airflow-airflow-config
---
# Source: airflow/templates/jobs/migrate-database-job.yaml


################################
## Airflow Run Migrations
#################################
apiVersion: batch/v1
kind: Job
metadata:
  name: my-airflow-run-airflow-migrations
  labels:
    tier: airflow
    component: run-airflow-migrations
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
    helm.sh/hook-weight: "1"
spec:
  template:
    metadata:
      labels:
        tier: airflow
        component: run-airflow-migrations
        release: my-airflow
    spec:
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      restartPolicy: OnFailure
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      serviceAccountName: my-airflow-migrate-database-job
      containers:
        - name: run-airflow-migrations
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - |-
              exec \
              airflow db upgrade
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: my-airflow-airflow-config
MANIFEST:
---
# Source: airflow/templates/flower/flower-serviceaccount.yaml


######################################
## Airflow Flower ServiceAccount
######################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-flower
  labels:
    tier: airflow
    component: flower
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/jobs/create-user-job-serviceaccount.yaml


###########################################
## Airflow Create User Job ServiceAccount
###########################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-create-user-job
  labels:
    tier: airflow
    component: create-user-job
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/jobs/migrate-database-job-serviceaccount.yaml


#############################################
## Airflow Migrate Database Job ServiceAccount
##############################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-migrate-database-job
  labels:
    tier: airflow
    component: run-airflow-migrations
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/redis/redis-serviceaccount.yaml


######################################
## Airflow Redis ServiceAccount
######################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-redis
  labels:
    tier: airflow
    component: redis
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/scheduler/scheduler-serviceaccount.yaml


################################
## Airflow Scheduler ServiceAccount
#################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-scheduler
  labels:
    tier: airflow
    component: scheduler
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/statsd/statsd-serviceaccount.yaml


######################################
## Airflow StatsD ServiceAccount
######################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-statsd
  labels:
    tier: airflow
    component: statsd
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/triggerer/triggerer-serviceaccount.yaml


################################
## Airflow Triggerer ServiceAccount
#################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-triggerer
  labels:
    tier: airflow
    component: triggerer
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/webserver/webserver-serviceaccount.yaml


######################################
## Airflow Webserver ServiceAccount
######################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-webserver
  labels:
    tier: airflow
    component: webserver
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/templates/workers/worker-serviceaccount.yaml


################################
## Airflow Worker ServiceAccount
#################################
kind: ServiceAccount
apiVersion: v1
metadata:
  name: my-airflow-worker
  labels:
    tier: airflow
    component: worker
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
---
# Source: airflow/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-airflow-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.5.3
    app.kubernetes.io/instance: my-airflow
    app.kubernetes.io/managed-by: Helm
  namespace: default
type: Opaque
data:
  postgresql-password: "cG9zdGdyZXM="
---
# Source: airflow/templates/secrets/metadata-connection-secret.yaml


################################
## Airflow Metadata Secret
#################################

kind: Secret
apiVersion: v1
metadata:
  name: my-airflow-airflow-metadata
  labels:
    tier: airflow
    release: my-airflow
    chart: airflow
    heritage: Helm
type: Opaque
data:
  connection: "cG9zdGdyZXNxbDovL3Bvc3RncmVzOnBvc3RncmVzQG15LWFpcmZsb3ctcG9zdGdyZXNxbC5kZWZhdWx0OjU0MzIvcG9zdGdyZXM/c3NsbW9kZT1kaXNhYmxl"
---
# Source: airflow/templates/secrets/result-backend-connection-secret.yaml


################################
## Airflow Result Backend Secret
#################################
kind: Secret
apiVersion: v1
metadata:
  name: my-airflow-airflow-result-backend
  labels:
    tier: airflow
    release: my-airflow
    chart: airflow
    heritage: Helm
type: Opaque
data:
  connection: "ZGIrcG9zdGdyZXNxbDovL3Bvc3RncmVzOnBvc3RncmVzQG15LWFpcmZsb3ctcG9zdGdyZXNxbDo1NDMyL3Bvc3RncmVzP3NzbG1vZGU9ZGlzYWJsZQ=="
---
# Source: airflow/templates/secrets/webserver-secret-key-secret.yaml


############################################
## Airflow Webserver Flask Secret Key Secret
############################################

kind: Secret
apiVersion: v1
metadata:
  name: my-airflow-webserver-secret-key
  labels:
    tier: airflow
    component: webserver
    release: my-airflow
    chart: airflow
    heritage: Helm
type: Opaque
data:
  webserver-secret-key: "TmxGQlExZHlWbG81UzJ4UlZrRlNjR0Z5VlZaWFIzcDVVVWh4T0dkV05Waz0="
---
# Source: airflow/templates/configmaps/configmap.yaml


################################
## Airflow ConfigMap
#################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-airflow-airflow-config
  labels:
    tier: airflow
    component: config
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
data:
  # These are system-specified config overrides.
  airflow.cfg: |-
    [celery]
    worker_concurrency = 16
    
    [celery_kubernetes_executor]
    kubernetes_queue = kubernetes
    
    [core]
    colored_console_log = False
    dags_folder = /opt/airflow/dags
    executor = CeleryExecutor
    load_examples = False
    remote_logging = False
    
    [elasticsearch]
    json_format = True
    log_id_template = {dag_id}_{task_id}_{execution_date}_{try_number}
    
    [elasticsearch_configs]
    max_retries = 3
    retry_timeout = True
    timeout = 30
    
    [kerberos]
    ccache = /var/kerberos-ccache/cache
    keytab = /etc/airflow.keytab
    principal = airflow@FOO.COM
    reinit_frequency = 3600
    
    [kubernetes]
    airflow_configmap = my-airflow-airflow-config
    airflow_local_settings_configmap = my-airflow-airflow-config
    multi_namespace_mode = False
    namespace = default
    pod_template_file = /opt/airflow/pod_templates/pod_template_file.yaml
    worker_container_repository = apache/airflow
    worker_container_tag = 2.2.4
    
    [logging]
    colored_console_log = False
    remote_logging = False
    
    [metrics]
    statsd_host = my-airflow-statsd
    statsd_on = True
    statsd_port = 9125
    statsd_prefix = airflow
    
    [scheduler]
    run_duration = 41460
    statsd_host = my-airflow-statsd
    statsd_on = True
    statsd_port = 9125
    statsd_prefix = airflow
    
    [webserver]
    enable_proxy_fix = True
    rbac = True
    
  airflow_local_settings.py: |
    
    
    from airflow.www.utils import UIAlert
    
    DASHBOARD_UIALERTS = [
      UIAlert(
        'Usage of a dynamic webserver secret key detected. We recommend a static webserver secret key instead.'
        ' See the <a href='
        '"https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key">'
        'Helm Chart Production Guide</a> for more details.',
        category="warning",
        roles=["Admin"],
        html=True,
      )
    ]
---
# Source: airflow/templates/rbac/pod-launcher-role.yaml


################################
## Airflow Pod Launcher Role
#################################
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-airflow-pod-launcher-role
  namespace: "default"
  labels:
    tier: airflow
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - "pods"
    verbs:
      - "create"
      - "list"
      - "get"
      - "patch"
      - "watch"
      - "delete"
  - apiGroups:
      - ""
    resources:
      - "pods/log"
    verbs:
      - "get"
  - apiGroups:
      - ""
    resources:
      - "pods/exec"
    verbs:
      - "create"
      - "get"
  - apiGroups:
      - ""
    resources:
      - "events"
    verbs:
      - "list"
---
# Source: airflow/templates/rbac/pod-log-reader-role.yaml


################################
## Airflow Pod Reader Role
#################################
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-airflow-pod-log-reader-role
  namespace: "default"
  labels:
    tier: airflow
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - "pods"
    verbs:
      - "list"
      - "get"
      - "watch"
  - apiGroups:
      - ""
    resources:
      - "pods/log"
    verbs:
      - "get"
      - "list"
---
# Source: airflow/templates/rbac/pod-launcher-rolebinding.yaml


################################
## Airflow Pod Launcher Role Binding
#################################
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: "default"
  name: my-airflow-pod-launcher-rolebinding
  labels:
    tier: airflow
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-airflow-pod-launcher-role
subjects:
  - kind: ServiceAccount
    name: my-airflow-worker
    namespace: "default"
---
# Source: airflow/templates/rbac/pod-log-reader-rolebinding.yaml


################################
## Airflow Pod Reader Role Binding
#################################
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: "default"
  name: my-airflow-pod-log-reader-rolebinding
  labels:
    tier: airflow
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-airflow-pod-log-reader-role
subjects:
  - kind: ServiceAccount
    name: my-airflow-webserver
    namespace: "default"
  - kind: ServiceAccount
    name: my-airflow-triggerer
    namespace: "default"
---
# Source: airflow/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-airflow-postgresql-headless
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.5.3
    app.kubernetes.io/instance: my-airflow
    app.kubernetes.io/managed-by: Helm
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  namespace: default
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-airflow
---
# Source: airflow/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-airflow-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.5.3
    app.kubernetes.io/instance: my-airflow
    app.kubernetes.io/managed-by: Helm
  annotations:
  namespace: default
spec:
  type: ClusterIP
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-airflow
    role: primary
---
# Source: airflow/templates/flower/flower-service.yaml


################################
## Airflow Flower Service Component
#################################
kind: Service
apiVersion: v1
metadata:
  name: my-airflow-flower
  labels:
    tier: airflow
    component: flower
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: flower
    release: my-airflow
  ports:
  
    -
      name: flower-ui
      port: 5555
---
# Source: airflow/templates/redis/redis-service.yaml


################################
## Airflow Redis Service
#################################
kind: Service
apiVersion: v1
metadata:
  name: my-airflow-redis
  labels:
    tier: airflow
    component: redis
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: redis
    release: my-airflow
  ports:
    - name: redis-db
      protocol: TCP
      port: 6379
      targetPort: 6379
---
# Source: airflow/templates/statsd/statsd-service.yaml


################################
## Airflow StatsD Service
#################################
kind: Service
apiVersion: v1
metadata:
  name: my-airflow-statsd
  labels:
    tier: airflow
    component: statsd
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9102"
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: statsd
    release: my-airflow
  ports:
    - name: statsd-ingest
      protocol: UDP
      port: 9125
      targetPort: 9125
    - name: statsd-scrape
      protocol: TCP
      port: 9102
      targetPort: 9102
---
# Source: airflow/templates/webserver/webserver-service.yaml


################################
## Airflow Webserver Service
#################################
kind: Service
apiVersion: v1
metadata:
  name: my-airflow-webserver
  labels:
    tier: airflow
    component: webserver
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: webserver
    release: my-airflow
  ports:
  
    -
      name: airflow-ui
      port: 8080
---
# Source: airflow/templates/workers/worker-service.yaml


################################
## Airflow Worker Service
#################################
kind: Service
apiVersion: v1
metadata:
  name: my-airflow-worker
  labels:
    tier: airflow
    component: worker
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  clusterIP: None
  selector:
    tier: airflow
    component: worker
    release: my-airflow
  ports:
    - name: worker-logs
      protocol: TCP
      port: 8793
      targetPort: 8793
---
# Source: airflow/templates/flower/flower-deployment.yaml


################################
## Airflow Flower Deployment
#################################
kind: Deployment
apiVersion: apps/v1
metadata:
  name: my-airflow-flower
  labels:
    tier: airflow
    component: flower
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: flower
      release: my-airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: flower
        release: my-airflow
      annotations:
        checksum/airflow-config: f2dd7a94e719071426d91f1bd7bd12fe4fefd37cb31d3c30e09825ccba5f5d77
        checksum/flower-secret: 636da6aef52b0ab4a7d967a0eca8a89d7297308d564677a473605a5bab7e2d74
    spec:
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      serviceAccountName: my-airflow-flower
      restartPolicy: Always
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      containers:
        - name: flower
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - |-
              exec \
              airflow celery flower
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
          ports:
            - name: flower-ui
              containerPort: 5555
          livenessProbe:
            failureThreshold: 10
            exec:
              command:
                - curl
                - localhost:5555
            initialDelaySeconds: 10
            periodSeconds: 5
          readinessProbe:
            failureThreshold: 10
            exec:
              command:
                - curl
                - localhost:5555
            initialDelaySeconds: 10
            periodSeconds: 5
          envFrom:          
            []
          env:          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env
      volumes:
        - name: config
          configMap:
            name: my-airflow-airflow-config
---
# Source: airflow/templates/scheduler/scheduler-deployment.yaml


################################
## Airflow Scheduler Deployment/StatefulSet
#################################

# Are we using a local executor?
# Is persistence enabled on the _workers_?
# This is important because in $local mode, the scheduler assumes the role of the worker
# If we're using a StatefulSet
# If we're using elasticsearch logging

kind: Deployment
apiVersion: apps/v1
metadata:
  name: my-airflow-scheduler
  labels:
    tier: airflow
    component: scheduler
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: scheduler
      release: my-airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: scheduler
        release: my-airflow
      annotations:
        checksum/metadata-secret: 771518ae0870b8cfbf0f57b02c0043d334a2ef5550371b58d889ea74d9a161bb
        checksum/result-backend-secret: 6eed75ad1bf3d777ec2cb96d2e4f4fc10b14ce604d54da46e05304f549bbcf40
        checksum/pgbouncer-config-secret: da52bd1edfe820f0ddfacdebb20a4cc6407d296ee45bcb500a6407e2261a5ba2
        checksum/airflow-config: f2dd7a94e719071426d91f1bd7bd12fe4fefd37cb31d3c30e09825ccba5f5d77
        checksum/extra-configmaps: 2e44e493035e2f6a255d08f8104087ff10d30aef6f63176f1b18f75f73295598
        checksum/extra-secrets: bb91ef06ddc31c0c5a29973832163d8b0b597812a793ef911d33b622bc9d1655
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: scheduler
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      restartPolicy: Always
      terminationGracePeriodSeconds: 10
      serviceAccountName: my-airflow-scheduler
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
          args:          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
      containers:
        # Always run the main scheduler container.
        - name: scheduler
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - exec airflow scheduler
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -Wignore -c "
                  import os
                  os.environ['AIRFLOW__CORE__LOGGING_LEVEL'] = 'ERROR'
                  os.environ['AIRFLOW__LOGGING__LOGGING_LEVEL'] = 'ERROR'
                  from airflow.jobs.scheduler_job import SchedulerJob
                  from airflow.utils.db import create_session
                  from airflow.utils.net import get_hostname
                  import sys
                  with create_session() as session:
                      job = session.query(SchedulerJob).filter_by(hostname=get_hostname()).order_by(
                          SchedulerJob.latest_heartbeat.desc()).limit(1).first()
                  sys.exit(0 if job.is_alive() else 1)"
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: /opt/airflow/pod_templates/pod_template_file.yaml
              subPath: pod_template_file.yaml
              readOnly: true
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
        - name: scheduler-log-groomer
          resources:
            {}
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - /clean-logs
          
          env:
            - name: AIRFLOW__LOG_RETENTION_DAYS
              value: "15"
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
      volumes:
        - name: config
          configMap:
            name: my-airflow-airflow-config
        - name: logs
          emptyDir: {}
---
# Source: airflow/templates/statsd/statsd-deployment.yaml


################################
## Airflow StatsD Deployment
#################################
kind: Deployment
apiVersion: apps/v1
metadata:
  name: my-airflow-statsd
  labels:
    tier: airflow
    component: statsd
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: statsd
      release: my-airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: statsd
        release: my-airflow
    spec:
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      serviceAccountName: my-airflow-statsd
      securityContext: 
        runAsUser: 65534
      restartPolicy: Always
      containers:
        - name: statsd
          image: apache/airflow:airflow-statsd-exporter-2021.04.28-v0.17.0
          imagePullPolicy: IfNotPresent
          args:
            - "--statsd.mapping-config=/etc/statsd-exporter/mappings.yml"
          resources:
            {}
          ports:
            - name: statsd-ingest
              protocol: UDP
              containerPort: 9125
            - name: statsd-scrape
              containerPort: 9102
          livenessProbe:
            httpGet:
              path: /metrics
              port: 9102
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /metrics
              port: 9102
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
---
# Source: airflow/templates/triggerer/triggerer-deployment.yaml


################################
## Airflow Triggerer Deployment
#################################
kind: Deployment
apiVersion: apps/v1
metadata:
  name: my-airflow-triggerer
  labels:
    tier: airflow
    component: triggerer
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: triggerer
      release: my-airflow
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 50%
  template:
    metadata:
      labels:
        tier: airflow
        component: triggerer
        release: my-airflow
      annotations:
        checksum/metadata-secret: 771518ae0870b8cfbf0f57b02c0043d334a2ef5550371b58d889ea74d9a161bb
        checksum/pgbouncer-config-secret: da52bd1edfe820f0ddfacdebb20a4cc6407d296ee45bcb500a6407e2261a5ba2
        checksum/airflow-config: f2dd7a94e719071426d91f1bd7bd12fe4fefd37cb31d3c30e09825ccba5f5d77
        checksum/extra-configmaps: 2e44e493035e2f6a255d08f8104087ff10d30aef6f63176f1b18f75f73295598
        checksum/extra-secrets: bb91ef06ddc31c0c5a29973832163d8b0b597812a793ef911d33b622bc9d1655
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: triggerer
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      terminationGracePeriodSeconds: 60
      restartPolicy: Always
      serviceAccountName: my-airflow-triggerer
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
          args:
          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:
          
            []
          env:
          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env
          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
      containers:
        - name: triggerer
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - exec airflow triggerer
          resources:
            
            {}
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          envFrom:
          
            []
          env:
          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env
          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -Wignore -c "
                  import os
                  os.environ['AIRFLOW__CORE__LOGGING_LEVEL'] = 'ERROR'
                  os.environ['AIRFLOW__LOGGING__LOGGING_LEVEL'] = 'ERROR'
                
                  from airflow.jobs.triggerer_job import TriggererJob
                  from airflow.utils.db import create_session
                  from airflow.utils.net import get_hostname
                  import sys
                
                  with create_session() as session:
                      job = session.query(TriggererJob).filter_by(hostname=get_hostname()).order_by(
                          TriggererJob.latest_heartbeat.desc()).limit(1).first()
                
                  sys.exit(0 if job.is_alive() else 1)
                  "
      volumes:
        - name: config
          configMap:
            name: my-airflow-airflow-config
        - name: logs
          emptyDir: {}
---
# Source: airflow/templates/webserver/webserver-deployment.yaml


################################
## Airflow Webserver Deployment
#################################
kind: Deployment
apiVersion: apps/v1
metadata:
  name: my-airflow-webserver
  labels:
    tier: airflow
    component: webserver
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  replicas: 1
  strategy:
    # Here we define the rolling update strategy
    # - maxSurge define how many pod we can add at a time
    # - maxUnavailable define how many pod can be unavailable
    #   during the rolling update
    # Setting maxUnavailable to 0 would make sure we have the appropriate
    # capacity during the rolling update.
    # You can also use percentage based value instead of integer.
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      tier: airflow
      component: webserver
      release: my-airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: webserver
        release: my-airflow
      annotations:
        checksum/metadata-secret: 771518ae0870b8cfbf0f57b02c0043d334a2ef5550371b58d889ea74d9a161bb
        checksum/pgbouncer-config-secret: da52bd1edfe820f0ddfacdebb20a4cc6407d296ee45bcb500a6407e2261a5ba2
        checksum/webserver-secret-key: c0ec12fd23d1cb046080638ee600ff93dcbb6bb8406d983ef6f257b6b5b02354
        checksum/airflow-config: f2dd7a94e719071426d91f1bd7bd12fe4fefd37cb31d3c30e09825ccba5f5d77
        checksum/webserver-config: 4a2281a4e3ed0cc5e89f07aba3c1bb314ea51c17cb5d2b41e9b045054a6b5c72
        checksum/extra-configmaps: 2e44e493035e2f6a255d08f8104087ff10d30aef6f63176f1b18f75f73295598
        checksum/extra-secrets: bb91ef06ddc31c0c5a29973832163d8b0b597812a793ef911d33b622bc9d1655
    spec:
      serviceAccountName: my-airflow-webserver
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: webserver
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      restartPolicy: Always
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
          args:          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
      containers:
        - name: webserver
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - exec airflow webserver
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: /opt/airflow/pod_templates/pod_template_file.yaml
              subPath: pod_template_file.yaml
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          ports:
            - name: airflow-ui
              containerPort: 8080
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 20
            periodSeconds: 5
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 20
            periodSeconds: 5
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
      volumes:
        - name: config
          configMap:
            name: my-airflow-airflow-config
---
# Source: airflow/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-airflow-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.5.3
    app.kubernetes.io/instance: my-airflow
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: default
spec:
  serviceName: my-airflow-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: my-airflow
      role: primary
  template:
    metadata:
      name: my-airflow-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-10.5.3
        app.kubernetes.io/instance: my-airflow
        app.kubernetes.io/managed-by: Helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: my-airflow
                    app.kubernetes.io/component: primary
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: my-airflow-postgresql
          image: docker.io/bitnami/postgresql:11.12.0-debian-10-r44
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-airflow-postgresql
                  key: postgresql-password
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: airflow/templates/redis/redis-statefulset.yaml


################################
## Airflow Redis StatefulSet
#################################
kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: my-airflow-redis
  labels:
    tier: airflow
    component: redis
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  serviceName: my-airflow-redis
  selector:
    matchLabels:
      tier: airflow
      component: redis
      release: my-airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: redis
        release: my-airflow
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      serviceAccountName: my-airflow-redis
      containers:
        - name: redis
          image: redis:6-bullseye
          imagePullPolicy: IfNotPresent
          command: ["/bin/sh"]
          resources:
            {}
          args: ["-c", "redis-server --requirepass ${REDIS_PASSWORD}"]
          ports:
            - name: redis-db
              containerPort: 6379
          volumeMounts:
            - name: redis-db
              mountPath: /data
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-airflow-redis-password
                  key: password
  volumeClaimTemplates:
    - metadata:
        name: redis-db
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 1Gi
---
# Source: airflow/templates/workers/worker-deployment.yaml


################################
## Airflow Worker Deployment
#################################
kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: my-airflow-worker
  labels:
    tier: airflow
    component: worker
    release: my-airflow
    chart: "airflow-1.5.0"
    heritage: Helm
spec:
  serviceName: my-airflow-worker
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: worker
      release: my-airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: worker
        release: my-airflow
      annotations:
        checksum/metadata-secret: 771518ae0870b8cfbf0f57b02c0043d334a2ef5550371b58d889ea74d9a161bb
        checksum/result-backend-secret: 6eed75ad1bf3d777ec2cb96d2e4f4fc10b14ce604d54da46e05304f549bbcf40
        checksum/pgbouncer-config-secret: da52bd1edfe820f0ddfacdebb20a4cc6407d296ee45bcb500a6407e2261a5ba2
        checksum/webserver-secret-key: 6738db65b06ddd73f62b4080730ab5a074a0b9ff4bc163e575d38814e9c2dc06
        checksum/kerberos-keytab: 18b80c0921e5c0af1e63eca1c3ce3fbc388d006bd2db5a7ab512dc8a563b6443
        checksum/airflow-config: f2dd7a94e719071426d91f1bd7bd12fe4fefd37cb31d3c30e09825ccba5f5d77
        checksum/extra-configmaps: 2e44e493035e2f6a255d08f8104087ff10d30aef6f63176f1b18f75f73295598
        checksum/extra-secrets: bb91ef06ddc31c0c5a29973832163d8b0b597812a793ef911d33b622bc9d1655
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: worker
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      terminationGracePeriodSeconds: 600
      restartPolicy: Always
      serviceAccountName: my-airflow-worker
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
          args:          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
      containers:
        - name: worker
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - -c
            - |-
              exec \
              airflow celery worker
          resources:
            {}
          ports:
            - name: worker-logs
              containerPort: 8793
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          envFrom:          
            []
          env:
            # Only signal the main process, not the process group, to make Warm Shutdown work properly
            - name: DUMB_INIT_SETSID
              value: "0"          
            # Dynamically created environment variables
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-airflow-webserver-secret-key
                  key: webserver-secret-key
            # (Airflow 1.10.* variant)
            - name: AIRFLOW__CELERY__CELERY_RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              valueFrom:
                secretKeyRef:
                  name: my-airflow-airflow-result-backend
                  key: connection
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: my-airflow-broker-url
                  key: connection
        - name: worker-log-groomer
          image: apache/airflow:2.2.4
          imagePullPolicy: IfNotPresent
          args: 
            - bash
            - /clean-logs
          
          env:
            - name: AIRFLOW__LOG_RETENTION_DAYS
              value: "15"
          resources:
            {}
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
      volumes:
        - name: config
          configMap:
            name: my-airflow-airflow-config
  volumeClaimTemplates:
    - metadata:
        name: logs
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 100Gi
