---
# Source: spark/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: eureka-spark
  namespace: "default"
  labels:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: eureka

  annotations:
automountServiceAccountToken: true
---
# Source: spark/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: eureka-spark-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: eureka
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: eureka
---
# Source: spark/templates/svc-master.yaml
apiVersion: v1
kind: Service
metadata:
  name: eureka-spark-master-svc
  namespace: "default"
  labels:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: eureka
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - port: 7077
      targetPort: cluster
      name: cluster
    - port: 80
      targetPort: http
      name: http
      protocol: TCP
  selector:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: eureka
    app.kubernetes.io/component: master
---
# Source: spark/templates/statefulset-master.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: eureka-spark-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: eureka
    app.kubernetes.io/component: master
spec:
  serviceName: eureka-spark-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: spark
      app.kubernetes.io/instance: eureka
      app.kubernetes.io/component: master
  template:
    metadata:
      labels:
        app.kubernetes.io/name: spark
        app.kubernetes.io/instance: eureka
        app.kubernetes.io/component: master
    spec:
      
      serviceAccountName: eureka-spark
      affinity:
        podAffinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: spark
                    app.kubernetes.io/instance: eureka
                    app.kubernetes.io/component: master
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
      securityContext:
        fsGroup: 1001
        runAsGroup: 0
        runAsUser: 1001
        seLinuxOptions: {}
      containers:
        - name: spark-master
          image: kodumah/spark-master-2.4.0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: cluster
              containerPort: 7077
          volumeMounts:
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: SPARK_MODE
              value: "master"
            - name: SPARK_DAEMON_MEMORY
              value: ""
            - name: SPARK_MASTER_PORT
              value: "7077"
            - name: SPARK_MASTER_WEBUI_PORT
              value: "8080"
      #     envFrom:
      #     livenessProbe:
      #       failureThreshold: 6
      #       initialDelaySeconds: 180
      #       periodSeconds: 20
      #       successThreshold: 1
      #       timeoutSeconds: 5
      #       httpGet:
      #         path: /
      #         port: 8080
      #     readinessProbe:
      #       failureThreshold: 6
      #       initialDelaySeconds: 30
      #       periodSeconds: 10
      #       successThreshold: 1
      #       timeoutSeconds: 5
      #       httpGet:
      #         path: /
      #         port: 8080
      #     resources:
      #       limits: {}
      #       requests: {}
      # volumes:
---
# Source: spark/templates/statefulset-worker.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: eureka-spark-worker
  namespace: "default"
  labels:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: eureka
    app.kubernetes.io/component: worker
spec:
  serviceName: eureka-spark-headless
  replicas: 2
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: spark
      app.kubernetes.io/instance: eureka
      app.kubernetes.io/component: worker
  template:
    metadata:
      labels:
        app.kubernetes.io/name: spark
        app.kubernetes.io/instance: eureka
        app.kubernetes.io/component: worker
    spec:
      
      serviceAccountName: eureka-spark
      affinity:
        podAffinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: spark
                    app.kubernetes.io/instance: eureka
                    app.kubernetes.io/component: worker
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:  
      securityContext:
        fsGroup: 1001
        runAsGroup: 0
        runAsUser: 1001
        seLinuxOptions: {}
      containers:
        - name: spark-worker
          image: kodumah/spark-worker-2.4.0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          volumeMounts:
          env:
            - name: SPARK_MODE
              value: "worker"
            - name: BITNAMI_DEBUG
              value: "false"
            - name: SPARK_DAEMON_MEMORY
              value: ""
            ## There are some environment variables whose existence needs
            ## to be checked because Spark checks if they are null instead of an
            ## empty string
            - name: SPARK_WORKER_WEBUI_PORT
              value: "8080"
            - name: SPARK_DAEMON_JAVA_OPTS
              value: ""
            - name: SPARK_MASTER_URL
              value: spark://eureka-spark-master-svc:7077
            # If you use a custom properties file, it must be loaded using a ConfigMap
            - name: SPARK_WORKER_OPTS
              value: 
          envFrom:
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 180
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: 8080
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: 8080
          startupProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: 8080
          resources:
            limits: {}
            requests: {}
      volumes: